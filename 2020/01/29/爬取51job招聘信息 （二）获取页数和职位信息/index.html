<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>爬取51job招聘信息 （二）获取页数和职位信息 | Syficy</title><meta name="description" content="爬取51job招聘信息 （二）获取页数和职位信息"><meta name="keywords" content="爬虫"><meta name="author" content="Shen Yufan"><meta name="copyright" content="Shen Yufan"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="爬取51job招聘信息 （二）获取页数和职位信息"><meta name="twitter:description" content="爬取51job招聘信息 （二）获取页数和职位信息"><meta name="twitter:image" content="http://google.syficy.com:9002/?/images/2020/03/14/nsqcCl0N0Y/5.jpg"><meta property="og:type" content="article"><meta property="og:title" content="爬取51job招聘信息 （二）获取页数和职位信息"><meta property="og:url" content="http://syficy.com/2020/01/29/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%BA%8C%EF%BC%89%E8%8E%B7%E5%8F%96%E9%A1%B5%E6%95%B0%E5%92%8C%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF/"><meta property="og:site_name" content="Syficy"><meta property="og:description" content="爬取51job招聘信息 （二）获取页数和职位信息"><meta property="og:image" content="http://google.syficy.com:9002/?/images/2020/03/14/nsqcCl0N0Y/5.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://syficy.com/2020/01/29/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%BA%8C%EF%BC%89%E8%8E%B7%E5%8F%96%E9%A1%B5%E6%95%B0%E5%92%8C%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF/"><link rel="prev" title="爬取51job招聘信息 （三）入库与配置程序" href="http://syficy.com/2020/01/30/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%B8%89%EF%BC%89%E5%85%A5%E5%BA%93%E4%B8%8E%E9%85%8D%E7%BD%AE%E7%A8%8B%E5%BA%8F/"><link rel="next" title="爬取51job招聘信息 （一）获取城市id" href="http://syficy.com/2020/01/28/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%B8%80%EF%BC%89%E8%8E%B7%E5%8F%96%E5%9F%8E%E5%B8%82id/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://www.syficy.com","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: {"languages":{"author":"Author: Shen Yufan","link":"Link: http://syficy.com/2020/01/29/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%BA%8C%EF%BC%89%E8%8E%B7%E5%8F%96%E9%A1%B5%E6%95%B0%E5%92%8C%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF/","source":"Source: Syficy","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Syficy</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">30</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">12</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#爬取51job招聘信息-（二）获取页数和职位信息"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">爬取51job招聘信息 （二）获取页数和职位信息</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#获取总页数"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">[获取总页数]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#获取页面"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">[获取页面]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#获取职位详情"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">[获取职位详情]</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#爬取51job招聘信息-（二）获取页数和职位信息"><span class="toc-number">1.</span> <span class="toc-text">爬取51job招聘信息 （二）获取页数和职位信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#获取总页数"><span class="toc-number">1.1.</span> <span class="toc-text">[获取总页数]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#获取页面"><span class="toc-number">1.2.</span> <span class="toc-text">[获取页面]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#获取职位详情"><span class="toc-number">1.3.</span> <span class="toc-text">[获取职位详情]</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(http://google.syficy.com:9002/?/images/2020/03/14/nsqcCl0N0Y/5.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">爬取51job招聘信息 （二）获取页数和职位信息</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-01-29<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-01-21</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/">个人项目</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="爬取51job招聘信息-（二）获取页数和职位信息"><a href="#爬取51job招聘信息-（二）获取页数和职位信息" class="headerlink" title="爬取51job招聘信息 （二）获取页数和职位信息"></a>爬取51job招聘信息 （二）获取页数和职位信息</h1><p>[本文代码参考自 《实战python网络爬虫》-黄永强 2019.6月版本]<br>为保证时效性 对原书代码有较大修改 本文代码2019年10月7日有效<br>所有代码程序均仅用于学习，若无意伤害了您的个人利益请速与我联系删除</p>
<h2 id="获取总页数"><a href="#获取总页数" class="headerlink" title="[获取总页数]"></a>[获取总页数]</h2><p>上一节中我们已经获得了城市id，接下去就是通过城市id获取页数，以便后期爬取。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pageNumber</span><span class="params">(city_code, keyword)</span>:</span></span><br><span class="line">    url = <span class="string">'https://search.51job.com/list/'</span> + str(city_code) + <span class="string">',000000,0000,00,9,99,'</span>+str(keyword)+<span class="string">',2,1.html'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#driver = webdriver.Chrome()</span></span><br><span class="line">    <span class="comment">#driver.get(url)</span></span><br><span class="line">    <span class="comment">#os.system("pause")</span></span><br><span class="line">    </span><br><span class="line">    r = requests.get(url, headers = headers)</span><br><span class="line">    soup = BeautifulSoup(r.content.decode(<span class="string">'gbk'</span>),<span class="string">'html5lib'</span>)</span><br><span class="line">    find_page = soup.find(<span class="string">'div'</span>,class_ = <span class="string">'rt'</span>).getText()</span><br><span class="line">    find_page = find_page[<span class="number">5</span>::]</span><br><span class="line">    print(find_page)</span><br><span class="line">    temp = re.search(<span class="string">'\d+\.?\d*'</span>,find_page).group()</span><br><span class="line">    print(int(temp))</span><br><span class="line">    <span class="keyword">if</span> temp:</span><br><span class="line">        pageNumber = math.ceil(int(temp)/<span class="number">50</span>)</span><br><span class="line">        <span class="keyword">return</span> pageNumber</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></div>

<p>使用beautifulsoup模块，经过gbk解码 html5lib 后得到的 soup 在其中找到带rt class的 div  中可得到职位总数，其中，gbk可在页面的响应头中得到，在通过数据处理除去每页50得到结果，也可以直接使用下方的页面数，但是职位为0的时候页面数也会显示1，所以需要更多处理。<br>math.seil 即 天花板， 把数字往大了放， 同理math.floor 是把数字往小了放。</p>
<h2 id="获取页面"><a href="#获取页面" class="headerlink" title="[获取页面]"></a>[获取页面]</h2><p>我们可以发现1.html前的那个参数代表第几个页面，因此通过修改这个值可以获得不同的url，在通过beautifulsoup净化之后，在页面的p标签中得到50个详情url，然后尝试遍历这50个url的信息，得到我们要的职位详情。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(keyword,pageNumber)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> range(int(pageNumber)):</span><br><span class="line">        url = <span class="string">'https://search.51job.com/list/'</span> + str(city_code) + <span class="string">',000000,0000,00,9,99,'</span>+str(keyword)+<span class="string">',2,'</span>+str(p+<span class="number">1</span>)+<span class="string">'1.html'</span></span><br><span class="line">        r = requests.get(url,headers=headers)</span><br><span class="line">        soup = BeautifulSoup(r.content.decode(<span class="string">'gbk'</span>),<span class="string">'html5lib'</span>)</span><br><span class="line">        find_p = soup.find_all(<span class="string">'p'</span>,class_=re.compile(<span class="string">'t1'</span>))</span><br><span class="line">        print(find_p)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> find_p:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                info_dict = <span class="literal">None</span></span><br><span class="line">                print(i.find(<span class="string">'a'</span>)[<span class="string">'href'</span>])</span><br><span class="line">                url = i.find(<span class="string">'a'</span>)[<span class="string">'href'</span>]</span><br><span class="line">                info_dict = get_info(url)</span><br><span class="line">                print(info_dict)</span><br><span class="line">                <span class="keyword">if</span> info_dict:</span><br><span class="line">                    insert_db(info_dict)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">                time.sleep(<span class="number">5</span>)</span><br></pre></td></tr></table></figure></div>


<h2 id="获取职位详情"><a href="#获取职位详情" class="headerlink" title="[获取职位详情]"></a>[获取职位详情]</h2><p>由于有些职位详情页面不是51job的，所以我们要先判断是否为51job页面，否则无法使用相同的语法进行提取，我们先跳过这一部分职位。同样的美化我们的新详情url，并用一个字典存储我们想要的所有信息。</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_info</span><span class="params">(url)</span>:</span></span><br><span class="line">    temp_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'https://jobs.51job.com'</span> <span class="keyword">in</span> url:</span><br><span class="line">        r = requests.get(url, headers=headers)</span><br><span class="line">        time.sleep(<span class="number">1.5</span>)</span><br><span class="line">        soup = BeautifulSoup(r.content.decode(<span class="string">'gbk'</span>), <span class="string">'html5lib'</span>)</span><br><span class="line">        temp_dict[<span class="string">'job_id'</span>] = url.split(<span class="string">'.html'</span>)[<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        temp_dict[<span class="string">'company_name'</span>] = soup.find(<span class="string">'a'</span>, class_=<span class="string">'catn'</span>).getText().strip()</span><br><span class="line">        com_tag = soup.find(<span class="string">'div'</span>, class_=<span class="string">'com_tag'</span>).find_all(<span class="string">'p'</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> com_tag:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'i_flag'</span> <span class="keyword">in</span> str(i):</span><br><span class="line">                temp_dict[<span class="string">'company_type'</span>] = i.getText()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'i_people'</span> <span class="keyword">in</span> str(i):</span><br><span class="line">                temp_dict[<span class="string">'company_scale'</span>] = i.getText()</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'i_trade'</span> <span class="keyword">in</span> str(i):</span><br><span class="line">                temp_dict[<span class="string">'company_trade'</span>] = i.getText()</span><br><span class="line">        temp_dict[<span class="string">'job_name'</span>] = soup.find(<span class="string">'h1'</span>).getText().strip()</span><br><span class="line">        temp_dict[<span class="string">'job_pay'</span>] = soup.find(<span class="string">'div'</span>, class_=<span class="string">'cn'</span>).find(<span class="string">'strong'</span>).getText().strip()</span><br><span class="line">        msgltype = soup.find(<span class="string">'p'</span>, class_=<span class="string">'msg ltype'</span>).getText().split(<span class="string">'|'</span>)</span><br><span class="line">        education = [<span class="string">'初中'</span>, <span class="string">'中专'</span>, <span class="string">'中技'</span>, <span class="string">'大专'</span>, <span class="string">'高中'</span>, <span class="string">'本科'</span>, <span class="string">'硕士'</span>, <span class="string">'博士'</span>]</span><br><span class="line">        <span class="keyword">if</span> msgltype:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> msgltype:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">'经验'</span> <span class="keyword">in</span> i.strip():</span><br><span class="line">                    temp_dict[<span class="string">'job_years'</span>] = i.strip()</span><br><span class="line">                <span class="keyword">elif</span> <span class="string">'人'</span> <span class="keyword">in</span> i.strip():</span><br><span class="line">                    temp_dict[<span class="string">'job_member'</span>] = i.strip()</span><br><span class="line">                <span class="keyword">elif</span> <span class="string">'发布'</span> <span class="keyword">in</span> i.strip():</span><br><span class="line">                    temp_dict[<span class="string">'job_date'</span>] = i.strip()</span><br><span class="line">                <span class="keyword">elif</span> i.strip() <span class="keyword">in</span> education:</span><br><span class="line">                    temp_dict[<span class="string">'job_education'</span>] = i.strip()</span><br><span class="line">        t1 = soup.find(<span class="string">'div'</span>, class_=<span class="string">'t1'</span>).find_all(<span class="string">'span'</span>)</span><br><span class="line">        welfare = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> t1:</span><br><span class="line">            welfare.append(i.getText().strip())</span><br><span class="line">        temp_dict[<span class="string">'company_welfare'</span>] = <span class="string">'/'</span>.join(welfare)</span><br><span class="line">        bmsg = soup.find(<span class="string">'div'</span>, class_=<span class="string">'bmsg inbox'</span>)</span><br><span class="line">        <span class="keyword">if</span> bmsg:</span><br><span class="line">            <span class="keyword">if</span> bmsg.find(<span class="string">'p'</span>, class_=<span class="string">"fp"</span>):</span><br><span class="line">                temp_dict[<span class="string">'job_location'</span>] = bmsg.find(<span class="string">'p'</span>, class_=<span class="string">"fp"</span>).getText().strip()</span><br><span class="line">        find_describe = soup.find(<span class="string">'div'</span>, class_=<span class="string">'bmsg job_msg inbox'</span>)</span><br><span class="line">        temp = str(find_describe).split(<span class="string">'&lt;div class="mt10"&gt;'</span>)[<span class="number">0</span>]</span><br><span class="line">        Mysoup = BeautifulSoup(temp, <span class="string">'html5lib'</span>)</span><br><span class="line">        temp_dict[<span class="string">'job_describe'</span>] = Mysoup.getText().strip()</span><br><span class="line">        temp_dict[<span class="string">'recruit_sources'</span>] = <span class="string">'前程无忧'</span></span><br><span class="line">        <span class="keyword">return</span> temp_dict</span><br></pre></td></tr></table></figure></div>



</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Shen Yufan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://syficy.com/2020/01/29/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%BA%8C%EF%BC%89%E8%8E%B7%E5%8F%96%E9%A1%B5%E6%95%B0%E5%92%8C%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF/">http://syficy.com/2020/01/29/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%BA%8C%EF%BC%89%E8%8E%B7%E5%8F%96%E9%A1%B5%E6%95%B0%E5%92%8C%E8%81%8C%E4%BD%8D%E4%BF%A1%E6%81%AF/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫    </a></div><div class="post_share"><div class="social-share" data-image="http://google.syficy.com:9002/?/images/2020/03/14/nsqcCl0N0Y/5.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/01/30/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%B8%89%EF%BC%89%E5%85%A5%E5%BA%93%E4%B8%8E%E9%85%8D%E7%BD%AE%E7%A8%8B%E5%BA%8F/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>爬取51job招聘信息 （三）入库与配置程序</span></div></a></div><div class="next-post pull_right"><a href="/2020/01/28/%E7%88%AC%E5%8F%9651job%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%20%EF%BC%88%E4%B8%80%EF%BC%89%E8%8E%B7%E5%8F%96%E5%9F%8E%E5%B8%82id/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>爬取51job招聘信息 （一）获取城市id</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/01/21/基于selenium模块爬虫的百度知道自动答题/" title="基于selenium模块爬虫的百度知道自动答题"><img class="relatedPosts_cover lazyload"data-src="http://google.syficy.com:9002/?/images/2020/03/14/nsqcCl0N0Y/5.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-01-21</div><div class="relatedPosts_title">基于selenium模块爬虫的百度知道自动答题</div></div></a></div><div class="relatedPosts_item"><a href="/2020/01/28/爬取51job招聘信息 （一）获取城市id/" title="爬取51job招聘信息 （一）获取城市id"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-01-28</div><div class="relatedPosts_title">爬取51job招聘信息 （一）获取城市id</div></div></a></div><div class="relatedPosts_item"><a href="/2020/01/30/爬取51job招聘信息 （三）入库与配置程序/" title="爬取51job招聘信息 （三）入库与配置程序"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-01-30</div><div class="relatedPosts_title">爬取51job招聘信息 （三）入库与配置程序</div></div></a></div><div class="relatedPosts_item"><a href="/2020/02/04/解决python selenium中使用cookie登入报错 invalid argument_ invalid ‘expiry’/" title="解决python selenium中使用cookie登入报错 invalid argument_ invalid ‘expiry’"><img class="relatedPosts_cover lazyload"data-src="http://google.syficy.com:9002/?/images/2020/03/14/KXVq8jcQkd/4.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-02-04</div><div class="relatedPosts_title">解决python selenium中使用cookie登入报错 invalid argument_ invalid ‘expiry’</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Shen Yufan</div><div class="framework-info"><span></span></div><div class="icp"><a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"><span>浙ICP备19006500号-2</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>